{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Moth():\n",
    "    def __init__(self, X = [85, 196, 341, 578], num_iteration=100) -> None:\n",
    "        self.X = np.array(X)\n",
    "        self.sum_ = np.sum(X)\n",
    "        self.n = np.zeros(9)\n",
    "        self.p = 1/3*np.ones(3)\n",
    "        self.num_iteration = num_iteration\n",
    "\n",
    "    def E_step(self, x, p):\n",
    "        dom_p1 = p[0]**2+2*p[0]*p[1]+2*p[0]*p[2]\n",
    "        dom_p2 = p[1]**2+2*p[1]*p[2]\n",
    "        dom_p3 = dom_p2+p[2]**2\n",
    "\n",
    "        n_cc = x[0]*p[0]**2/dom_p1\n",
    "        n_ci = 2*x[0]*p[0]*p[1]/dom_p1\n",
    "        n_ct = 2*x[0]*p[0]*p[2]/dom_p1\n",
    "        n_ii = x[1]*p[1]**2/dom_p2\n",
    "        n_it = 2*x[1]*p[1]*p[2]/dom_p2\n",
    "        n_tt = x[2]\n",
    "        n_uii = x[3]*p[1]**2/dom_p3\n",
    "        n_uit = 2*x[3]*p[1]*p[2]/dom_p3\n",
    "        n_utt = x[3]*p[2]**2/dom_p3\n",
    "\n",
    "        n = np.array([n_cc, n_ci, n_ct, n_ii, n_it, n_tt, n_uii, n_uit, n_utt])\n",
    "        \n",
    "        return n\n",
    "    \n",
    "    def M_step(self, x, n):\n",
    "        sum_ = np.sum(x)\n",
    "        p_c = (2*n[0]+n[1]+n[2])/(2*sum_)\n",
    "        p_i = (2*n[3]+n[4]+n[1]+2*n[6]+n[7])/(2*sum_)\n",
    "        p_t = (2*n[5]+n[4]+n[2]+2*n[8]+n[7])/(2*sum_)\n",
    "        p = np.array([p_c, p_i, p_t])\n",
    "\n",
    "        return p\n",
    "    \n",
    "    def l(self, x, p):\n",
    "        return x[0]*np.log(p[0]**2 + 2*p[0]*p[1] + 2*p[0]*p[2]) + x[1]*np.log(p[1]**2+2*p[1]*p[2]) + 2*x[2]*np.log(p[2]) + 2*x[3]*np.log(p[1]+p[2])\n",
    "    \n",
    "    def grad_Q(self, n, p):\n",
    "        dp_c = (2*n[0]+n[1]+n[2])/p[0] - (n[2]+n[4]+n[7]+2*(n[5]+n[8]))/p[2]\n",
    "        dp_i = (n[1]+2*(n[3]+n[6])+n[4]+n[7])/p[1] - (n[2]+n[4]+n[7]+2*(n[5]+n[8]))/p[2]\n",
    "        return np.array([dp_c, dp_i])\n",
    "    \n",
    "    def hessian_Q(self, n, p):\n",
    "        dp_cc = -(2*n[0]+n[1]+n[2])/(p[0]**2) - (n[2]+n[4]+n[7]+2*(n[5]+n[8]))/(p[2]**2)\n",
    "        dp_ci = -(n[2]+n[4]+n[7]+2*(n[5]+n[8]))/(p[2]**2)\n",
    "        dp_ii = -(n[1]+2*(n[3]+n[6])+n[4]+n[7])/(p[1]**2) - (n[2]+n[4]+n[7]+2*(n[5]+n[8]))/(p[2]**2)\n",
    "        return np.array([[dp_cc, dp_ci],[dp_ci, dp_ii]])\n",
    "    \n",
    "    def StepHalvingBacktracking(self, x, p0, D):\n",
    "        t_tmp = 1\n",
    "        p_dim = p0.shape[0]\n",
    "        l0 = self.l(x, p0)\n",
    "        tmp_p = np.zeros(p0.shape)\n",
    "        tmp_p[:2] = p0[:2] + t_tmp*D\n",
    "        tmp_p[2] = 1 - np.sum(tmp_p[:2])\n",
    "        \n",
    "        while((np.sum(tmp_p >= 0)<p_dim) or (np.sum(tmp_p <= 1)<p_dim)):\n",
    "            t_tmp = 0.5*t_tmp\n",
    "            tmp_p = np.zeros(p0.shape)\n",
    "            tmp_p[:2] = p0[:2] + t_tmp*D\n",
    "            tmp_p[2] = 1 - np.sum(tmp_p[:2])\n",
    "\n",
    "        while(self.l(x, tmp_p) < l0):\n",
    "            t_tmp = 0.5*t_tmp\n",
    "            tmp_p = np.zeros(p0.shape)\n",
    "            tmp_p[:2] = p0[:2] + t_tmp*D\n",
    "            tmp_p[2] = 1 - np.sum(tmp_p[:2])\n",
    "\n",
    "        return tmp_p\n",
    "    \n",
    "    def gradient_M_step(self, x, n, p):\n",
    "        tmp_p = p.copy()\n",
    "        hessian_inv = np.linalg.inv(self.hessian_Q(n, tmp_p))\n",
    "        grad = self.grad_Q(n, tmp_p)\n",
    "        delta__nt = -hessian_inv@grad\n",
    "        tmp_p = self.StepHalvingBacktracking(x, tmp_p, delta__nt)\n",
    "\n",
    "        return tmp_p\n",
    "\n",
    "    def EM_algorithm(self, X, epsilon=1e-10, inplace=False):\n",
    "        n, p = self.n, self.p\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_n = self.E_step(X, p)\n",
    "            tmp_p = self.M_step(X, tmp_n)\n",
    "            delta_n = tmp_n - n\n",
    "            delta_p = tmp_p - p\n",
    "            p, n = tmp_p, tmp_n\n",
    "            error = np.sqrt(np.sum(delta_n**2)) + np.sqrt(np.sum(delta_p**2))\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.p, self.n = p, n\n",
    "\n",
    "        return p\n",
    "    \n",
    "    def BootStrap_p(self, num_bootstrap):\n",
    "        P = np.zeros((num_bootstrap, self.p.shape[0]))\n",
    "        for i in range(num_bootstrap):\n",
    "            n_c = np.random.binomial(self.sum_, self.X[0]/self.sum_, size=None)\n",
    "            n_i = np.random.binomial(self.sum_-n_c, self.X[1]/(self.sum_-n_c), size=None)\n",
    "            n_t = np.random.binomial(self.sum_-n_c-n_i, self.X[2]/(self.sum_-n_c-n_i), size=None)\n",
    "            n_u = self.sum_-n_c-n_t-n_i\n",
    "\n",
    "            x_generated = np.array([n_c, n_i, n_t, n_u])\n",
    "            p = self.EM_algorithm(x_generated, inplace=False)\n",
    "            P[i] = p\n",
    "            \n",
    "        return P\n",
    "    \n",
    "    def cal_p_statistic(self, num_bootstrap):\n",
    "        P = self.BootStrap_p(num_bootstrap)\n",
    "        p_mean = np.mean(P, axis=0)\n",
    "        p_std = np.std(P, axis=0)\n",
    "        cov = np.cov(P.T)\n",
    "        cor = np.corrcoef(P.T)\n",
    "        return p_mean, p_std, cov, cor\n",
    "    \n",
    "    def EM_gradient_algorithm(self, X, epsilon=1e-10, inplace=False):\n",
    "        n, p = self.n, self.p\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_n = self.E_step(X, p)\n",
    "            tmp_p = self.gradient_M_step(X, tmp_n, p)\n",
    "            delta_n = tmp_n - n\n",
    "            delta_p = tmp_p - p\n",
    "            p, n = tmp_p, tmp_n\n",
    "            error = np.sqrt(np.sum(delta_n**2)) + np.sqrt(np.sum(delta_p**2))\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.p, self.n = p, n\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [85, 196, 341, 578]\n",
    "moth = Moth(X, num_iteration=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM算法得到的p的MLE为: p_c = 0.036067, p_i = 0.195799, p_t = 0.768134\n"
     ]
    }
   ],
   "source": [
    "MLE_EM = moth.EM_algorithm(X, inplace=True)\n",
    "print(\"EM算法得到的p的MLE为: p_c = %f, p_i = %f, p_t = %f\"%(MLE_EM[0], MLE_EM[1], MLE_EM[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10000\n",
    "p_mean, p_std, p_cov, p_cor = moth.cal_p_statistic(num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boot strapping采样10000次后得到:\n",
      "p_c, p_i, p_t的标准差分别为0.003849, 0.011013, 0.011399\n",
      "p的相关系数矩阵为:\n",
      " [[ 1.         -0.07258155 -0.26749594]\n",
      " [-0.07258155  1.         -0.94160231]\n",
      " [-0.26749594 -0.94160231  1.        ]]\n",
      "可见, corr(p_c, p_i) = -0.072582, corr(p_c, p_t) = -0.267496, corr(p_i, p_t) = -0.941602\n"
     ]
    }
   ],
   "source": [
    "std_p_c, std_p_i, std_p_t = np.sqrt(p_cov[0,0]), np.sqrt(p_cov[1,1]), np.sqrt(p_cov[2,2])\n",
    "print(\"Boot strapping采样%d次后得到:\"%(num_iterations))\n",
    "print(\"p_c, p_i, p_t的标准差分别为%f, %f, %f\"%(std_p_c, std_p_i, std_p_t))\n",
    "print(\"p的相关系数矩阵为:\\n\", p_cor)\n",
    "print(\"可见, corr(p_c, p_i) = %f, corr(p_c, p_t) = %f, corr(p_i, p_t) = %f\"%(p_cor[0,1], p_cor[0,2], p_cor[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM gradient算法得到的p的MLE为: p_c = 0.036067, p_i = 0.195799, p_t = 0.768134\n"
     ]
    }
   ],
   "source": [
    "MLE_EM_grad = moth.EM_gradient_algorithm(X, inplace=False)\n",
    "print(\"EM gradient算法得到的p的MLE为: p_c = %f, p_i = %f, p_t = %f\"%(MLE_EM_grad[0], MLE_EM_grad[1], MLE_EM_grad[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HIV():\n",
    "    def __init__(self, X = [379,299,222,145,109,95,73,59,45,30,24,12,4,2,0,1,1], num_iteration=10000) -> None:\n",
    "        from scipy.special import gamma\n",
    "        self.X = np.array(X)\n",
    "        self.sum_ = np.sum(X)\n",
    "        self.alpha, self.beta, self.mu, self.lamda = 1/3, 1/3, 0.5, 0.5\n",
    "        self.theta = (self.alpha, self.beta, self.mu, self.lamda)\n",
    "\n",
    "        self.I = np.arange(0, self.X.shape[0], 1)\n",
    "        self.zi = np.zeros(self.I.shape[0])\n",
    "        self.ti = np.zeros(self.I.shape[0])\n",
    "        self.pi = np.zeros(self.I.shape[0])\n",
    "\n",
    "        self.F_gamma = gamma\n",
    "        self.num_iteration = num_iteration\n",
    "\n",
    "    def E_step(self, theta):\n",
    "        alpha, beta, mu, lamda = theta\n",
    "\n",
    "        I = np.arange(0, 17, 1)\n",
    "        zi = alpha*((I==0).astype(np.int32))\n",
    "        ti = beta*np.exp(-mu)*(mu**I)\n",
    "        pi = (1-alpha-beta)*np.exp(-lamda)*(lamda**I)\n",
    "        PI = zi+ti+pi\n",
    "\n",
    "        zi /= PI\n",
    "        ti /= PI\n",
    "        pi /= PI\n",
    "\n",
    "        return I, zi, ti, pi\n",
    "\n",
    "    def M_step(self, x, p):\n",
    "        I, zi, ti, pi = p\n",
    "\n",
    "        sum_ = np.sum(x)\n",
    "        alpha = np.sum(x[0]*zi)/sum_\n",
    "        beta = np.sum(x*ti)/sum_\n",
    "        mu = np.sum(I*x*ti)/np.sum(x*ti)\n",
    "        lamda = np.sum(I*x*pi)/np.sum(x*pi)\n",
    "        theta = (alpha, beta, mu, lamda)\n",
    "        \n",
    "        return theta\n",
    "\n",
    "    def EM_algorithm(self, X, epsilon=1e-10, inplace=False):\n",
    "        theta = (self.alpha, self.beta, self.mu, self.lamda)\n",
    "        p = self.I, self.zi, self.ti, self.pi\n",
    "\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_p = self.E_step(theta)\n",
    "            tmp_theta = self.M_step(X, tmp_p)\n",
    "            delta_theta = np.array(tmp_theta) - np.array(theta)\n",
    "            delta_p = np.concatenate([tmp_p[j] - p[j] for j in range(len(tmp_p))])\n",
    "            error = np.sqrt(np.sum(delta_theta**2)) + np.sqrt(np.sum(delta_p**2))\n",
    "            p, theta = tmp_p, tmp_theta\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.I, self.zi, self.ti, self.pi = p\n",
    "            self.theta = theta\n",
    "\n",
    "        return theta\n",
    "    \n",
    "    def BootStrap_theta(self, num_bootstrap):\n",
    "        P = np.zeros((num_bootstrap, len(self.theta)))\n",
    "        for i in range(num_bootstrap):\n",
    "            x_generated = np.zeros(self.X.shape)\n",
    "            x_sampled = np.random.choice(np.arange(self.X.shape[0]), np.sum(self.X), p=self.X/np.sum(self.X))\n",
    "            for j in range(x_generated.shape[0]):\n",
    "                x_generated[j] = np.where(x_sampled == j)[0].shape[0]\n",
    "            theta = self.EM_algorithm(x_generated, inplace=False)\n",
    "            P[i] = np.array(theta)\n",
    "            \n",
    "        return P\n",
    "    \n",
    "    def cal_p_statistic(self, num_bootstrap):\n",
    "        P = self.BootStrap_theta(num_bootstrap)\n",
    "        p_mean = np.mean(P, axis=0)\n",
    "        p_std = np.std(P, axis=0)\n",
    "        cov = np.cov(P.T)\n",
    "        cor = np.corrcoef(P.T)\n",
    "        return p_mean, p_std, cov, cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([379,299,222,145,109,95,73,59,45,30,24,12,4,2,0,1,1])\n",
    "hiv = HIV(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的alpha = 0.122166, beta = 0.562542, mu = 1.467475, lambda = 5.938889\n"
     ]
    }
   ],
   "source": [
    "theta_pred = hiv.EM_algorithm(data, inplace=True)\n",
    "print(\"预测的alpha = %f, beta = %f, mu = %f, lambda = %f\"%theta_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 2000\n",
    "theta_mean, theta_std, theta_cov, theta_cor = hiv.cal_p_statistic(num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boot strapping采样2000次后得到:\n",
      "alpha, beta, mu, lambda的标准差分别为0.044971, 0.089553, 1.290534, 1.426267\n",
      "theta的相关系数矩阵为:\n",
      " [[ 1.         -0.60861803  0.41425872 -0.42970013]\n",
      " [-0.60861803  1.         -0.9426542   0.96090041]\n",
      " [ 0.41425872 -0.9426542   1.         -0.97836479]\n",
      " [-0.42970013  0.96090041 -0.97836479  1.        ]]\n",
      "可见,\n",
      "corr(alpha, beta) = -0.608618,\tcorr(alpha, mu) = 0.414259,\tcorr(alpha, lambda) = -0.429700,\n",
      "corr(beta, mu) = -0.942654,\tcorr(beta, lambda) = 0.960900,\tcorr(mu, lambda) = -0.978365\n"
     ]
    }
   ],
   "source": [
    "std_alpha, std_beta, std_mu, std_lambda = np.sqrt(theta_cov[0,0]), np.sqrt(theta_cov[1,1]), np.sqrt(theta_cov[2,2]), np.sqrt(theta_cov[3,3])\n",
    "print(\"Boot strapping采样%d次后得到:\"%(num_iterations))\n",
    "print(\"alpha, beta, mu, lambda的标准差分别为%f, %f, %f, %f\"%(std_alpha, std_beta, std_mu, std_lambda))\n",
    "print(\"theta的相关系数矩阵为:\\n\", theta_cor)\n",
    "print(\"可见,\\ncorr(alpha, beta) = %f,\\tcorr(alpha, mu) = %f,\\tcorr(alpha, lambda) = %f,\\ncorr(beta, mu) = %f,\\tcorr(beta, lambda) = %f,\\tcorr(mu, lambda) = %f\"%(theta_cor[0,1], theta_cor[0,2], theta_cor[0,3], theta_cor[1,2], theta_cor[1,3], theta_cor[2,3]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripleNormal():\n",
    "    def __init__(self, data, num_iteration = 1000) -> None:\n",
    "        self.not_known = 0x7fffffff\n",
    "        self.data_normal = np.array(data.fillna(self.not_known))\n",
    "        self.not_known_idx1, self.not_known_idx2, self.not_known_idx3 = self.get_unknown_idx(self.data_normal)\n",
    "        self.konwn0 = np.where(np.array(self.data_normal[:,0])!=self.not_known)\n",
    "        self.konwn1 = np.where(np.array(self.data_normal[:,1])!=self.not_known)\n",
    "        self.konwn2 = np.where(np.array(self.data_normal[:,2])!=self.not_known)\n",
    "        self.known_all = np.intersect1d(self.konwn0, np.intersect1d(self.konwn1, self.konwn2))\n",
    "\n",
    "        self.mean = np.mean(self.data_normal[self.known_all], axis=0, keepdims=True)\n",
    "        self.cov= np.array([[1.0, 0.6, 1.2],\n",
    "                            [0.6, 0.5, 0.5],\n",
    "                            [1.2, 0.5, 3.0]])\n",
    "        self.alpha = np.array([[2,4,6]])\n",
    "        self.beta = np.array([[2,2,2]])\n",
    "\n",
    "        self.num_iteration = num_iteration\n",
    "\n",
    "    def get_unknown_idx(self, data):\n",
    "        not_known_idx = np.where(data == self.not_known)\n",
    "        not_knowns = [([], []), ([], []), ([], [])]\n",
    "        tmp_i = -1\n",
    "        tmp_js = []\n",
    "        for i, raw in enumerate(not_known_idx[0]):\n",
    "            if(raw!=tmp_i):\n",
    "                if(tmp_i != -1):\n",
    "                    tmp_len = len(tmp_js)\n",
    "                    not_knowns[tmp_len-1][0].append(tmp_i)\n",
    "                    not_knowns[tmp_len-1][1].append(tmp_js)\n",
    "                tmp_i = raw\n",
    "                tmp_js = []\n",
    "            tmp_js.append(not_known_idx[1][i])\n",
    "            if(i == not_known_idx[0].shape[0]-1):\n",
    "                tmp_len = len(tmp_js)\n",
    "                not_knowns[tmp_len-1][0].append(tmp_i)\n",
    "                not_knowns[tmp_len-1][1].append(tmp_js)\n",
    "\n",
    "        not_known_idx1 = not_knowns[0]\n",
    "        not_known_idx2 = not_knowns[1]\n",
    "        not_known_idx3 = not_knowns[2]\n",
    "\n",
    "        return not_known_idx1, not_known_idx2, not_known_idx3\n",
    "    \n",
    "    def value(self, data, mean, cov):\n",
    "        K = data.shape[1]\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "\n",
    "        tmp = data-mean\n",
    "        ret1 = -1/2*np.sum(K*np.log(2*np.pi)+np.log(np.linalg.det(cov)) + np.sum(tmp*(cov_inv@(tmp.T)), axis=1))\n",
    "        tmp2 = -(mean-alpha)/beta\n",
    "        ret2 = np.sum(tmp2 - np.log(beta) - 2*np.log(1+np.exp(tmp2)))\n",
    "\n",
    "        return ret1 + ret2\n",
    "    \n",
    "    def grad_sigma(self, data, mean, cov):\n",
    "        N = data.shape[0]\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "\n",
    "        ret1 = -1/2*N*cov_inv\n",
    "        tmp = data-mean\n",
    "        ret2 = -1/2*(tmp.T@tmp)\n",
    "\n",
    "        return ret1 + ret2\n",
    "    \n",
    "    def grad(self, data, mean, cov):\n",
    "        K = data.shape[1]\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "\n",
    "        ret1 = -np.sum((data-mean)@cov_inv, axis=0, keepdims=True)\n",
    "        ret2 = -1/beta + 2/(beta*(1+np.exp((mean-alpha)/beta)))\n",
    "\n",
    "        return ret1 + ret2\n",
    "    \n",
    "    def hessian(self, data, mean, cov):\n",
    "        K = data.shape[1]\n",
    "        N = data.shape[0]\n",
    "        cov_inv = np.linalg.inv(cov)\n",
    "        alpha = self.alpha\n",
    "        beta = self.beta\n",
    "\n",
    "        ret1 = cov_inv*N\n",
    "        tmp = np.exp((mean-alpha)/beta)\n",
    "        ret2 = -2*np.diag((tmp/((beta*(1+tmp))**2)))\n",
    "\n",
    "        return ret1 + ret2\n",
    "    \n",
    "    def cond_mean(self, data, mean, cov, unknown_indices, known_indices):\n",
    "        known_cov = cov[np.ix_(known_indices, known_indices)]\n",
    "        known_unknown_cov = cov[np.ix_(unknown_indices, known_indices, )]\n",
    "        unknown_cov = cov[np.ix_(unknown_indices, unknown_indices)]\n",
    "        known_values = data[known_indices]\n",
    "        conditional_mean = mean[0, unknown_indices] + known_unknown_cov @ np.linalg.inv(known_cov) @ (known_values - mean[0, known_indices])\n",
    "\n",
    "        return conditional_mean\n",
    "    \n",
    "    def cond_cov(self, data, mean, cov, unknown_indices, known_indices):\n",
    "        known_cov = cov[known_indices, known_indices]\n",
    "        known_unknown_cov = cov[known_indices, unknown_indices]\n",
    "        unknown_cov = cov[unknown_indices, unknown_indices]\n",
    "        conditional_cov = unknown_cov - known_unknown_cov @ np.linalg.inv(known_cov) @ known_unknown_cov.T\n",
    "\n",
    "        return conditional_cov\n",
    "\n",
    "    def E_step(self, data, mean, cov):\n",
    "        tmp_data = data.copy()\n",
    "        indices = np.arange(0,3,1).astype(np.int32)\n",
    "        for i, raw in enumerate(self.not_known_idx1[0]):\n",
    "            unknown_indices = np.array(self.not_known_idx1[1][i])\n",
    "            known_indices = np.setdiff1d(indices, unknown_indices)\n",
    "            cond_mean = self.cond_mean(tmp_data[raw], mean, cov, unknown_indices, known_indices)\n",
    "            tmp_data[raw, unknown_indices] = cond_mean\n",
    "\n",
    "        for i, raw in enumerate(self.not_known_idx2[0]):\n",
    "            unknown_indices = np.array(self.not_known_idx2[1][i])\n",
    "            known_indices = np.setdiff1d(indices, unknown_indices)\n",
    "            cond_mean = self.cond_mean(tmp_data[raw], mean, cov, unknown_indices, known_indices)\n",
    "            tmp_data[raw, unknown_indices] = cond_mean\n",
    "\n",
    "        for i, raw in enumerate(self.not_known_idx3[0]):\n",
    "            unknown_indices = np.array(self.not_known_idx3[1][i])\n",
    "            known_indices = np.setdiff1d(indices, unknown_indices)\n",
    "            cond_mean = self.cond_mean(tmp_data[raw], mean, cov, unknown_indices, known_indices)\n",
    "            tmp_data[raw, unknown_indices] = cond_mean\n",
    "\n",
    "        return tmp_data\n",
    "\n",
    "    def M_step(self, data):\n",
    "        mu = np.mean(data, axis=0, keepdims=True)\n",
    "        cov = np.cov(data.T)\n",
    "\n",
    "        return mu, cov\n",
    "    \n",
    "    def EM_algorithm(self, data, epsilon = 1e-10, inplace = False):\n",
    "        tmp_data = np.array(data.fillna(self.not_known))\n",
    "        mean = self.mean\n",
    "        cov = self.cov\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_data = self.E_step(tmp_data, mean, cov)\n",
    "            tmp_mean, tmp_cov = self.M_step(tmp_data)\n",
    "            delta_mean = tmp_mean - mean\n",
    "            delta_cov = tmp_cov - cov\n",
    "            error = np.sqrt(np.sum(delta_mean**2)) + np.sqrt(np.sum(delta_cov**2))\n",
    "            mean, cov = tmp_mean, tmp_cov\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.mean, self.cov, = mean ,cov\n",
    "            self.data = tmp_data\n",
    "\n",
    "        return mean, cov\n",
    "    \n",
    "    def gradient_M_step(self, data, fit_sigma = False, delta = 1e-10, learning_rate = 0.01):\n",
    "        mean = np.mean(data, axis=0)\n",
    "        cov = np.cov(data.T)\n",
    "        if(not fit_sigma): \n",
    "            cov = self.cov\n",
    "        error = 1\n",
    "        if(not fit_sigma):\n",
    "            while(error > delta):\n",
    "                grad = self.grad(data, mean, cov)\n",
    "                hessian = self.hessian(data, mean, cov)\n",
    "                hessian_inv = np.linalg.inv(hessian)\n",
    "                delta_mean = -grad@hessian_inv\n",
    "                mean = mean + delta_mean\n",
    "                error = np.sqrt(np.sum(delta_mean**2))\n",
    "        else:\n",
    "            while(error > delta):\n",
    "                grad = self.grad(data, mean, cov)\n",
    "                grad_sigma = self.grad_sigma(data, mean, cov)\n",
    "                print(grad_sigma)\n",
    "                hessian = self.hessian(data, mean, cov)\n",
    "                hessian_inv = np.linalg.inv(hessian)\n",
    "                delta_mean = -grad@hessian_inv\n",
    "                delta_sigma = learning_rate*grad_sigma\n",
    "                mean = mean + delta_mean\n",
    "                cov = cov + delta_sigma\n",
    "                error = np.sqrt(np.sum(delta_mean**2) + np.sqrt(np.sum(delta_sigma.T@delta_sigma)))\n",
    "                \n",
    "        return mean, cov\n",
    "\n",
    "    def EM_gradient_algorithm(self, data, epsilon=1e-10, inplace = False, fit_sigma = False):\n",
    "        tmp_data = np.array(data.fillna(self.not_known))\n",
    "        mean = self.mean\n",
    "        cov = self.cov\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_data = self.E_step(tmp_data, mean, cov)\n",
    "            tmp_mean, tmp_cov = self.gradient_M_step(tmp_data, fit_sigma = fit_sigma)\n",
    "            delta_mean = tmp_mean - mean\n",
    "            delta_cov = tmp_cov - cov\n",
    "            error = np.sqrt(np.sum(delta_mean**2)) + np.sqrt(np.sum(delta_cov**2))\n",
    "            mean, cov = tmp_mean, tmp_cov\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.mean, self.cov, = mean ,cov\n",
    "            self.data = tmp_data\n",
    "        return mean, cov"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x1</th>\n",
       "      <th>x2</th>\n",
       "      <th>x3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2.67</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.44</td>\n",
       "      <td>2.73</td>\n",
       "      <td>7.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.36</td>\n",
       "      <td>2.96</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.76</td>\n",
       "      <td>0.31</td>\n",
       "      <td>9.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     x1    x2    x3\n",
       "0   NaN  2.67   NaN\n",
       "1  0.44  2.73  7.68\n",
       "2  1.36  2.96   NaN\n",
       "3 -1.76  0.31  9.71\n",
       "4   NaN   NaN  9.49"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_normal = pd.read_csv(\"trivariatenormal.dat\", sep=\" \")\n",
    "data_normal.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tripnormal = TripleNormal(data_normal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的mu为:  [[0.87883229 2.85094528 9.02942437]]\n",
      "预测的sigma为:\n",
      " [[1.3511929  0.95683854 1.28486395]\n",
      " [0.95683854 0.73441359 0.69129236]\n",
      " [1.28486395 0.69129236 2.36967305]]\n"
     ]
    }
   ],
   "source": [
    "mu, sigma = tripnormal.EM_algorithm(data_normal, inplace = False)\n",
    "print(\"预测的mu为: \", mu)\n",
    "print(\"预测的sigma为:\\n\",sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM gradient方法预测的mu为:  [[0.8790627  2.8457106  9.03311281]]\n",
      "预测的sigma为:\n",
      " [[1.  0.6 1.2]\n",
      " [0.6 0.5 0.5]\n",
      " [1.2 0.5 3. ]]\n"
     ]
    }
   ],
   "source": [
    "mu_grad, sigma_grad = tripnormal.EM_gradient_algorithm(data_normal, inplace = False)\n",
    "print(\"EM gradient方法预测的mu为: \", mu_grad)\n",
    "print(\"预测的sigma为:\\n\",sigma_grad)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Coupling():\n",
    "    def __init__(self, \n",
    "                 data = np.array([6.94, 5.50, 4.54, 2.14, 3.65, 3.40, 4.38, 10.24, 4.56, 9.42, 4.55, 4.15, 5.64, 10.23]), \n",
    "                 mask = np.array([1,0,0,0,1,1,1,0,0,0,1,1,0,1]),\n",
    "                 a = 0.003,\n",
    "                 b = 2.5,\n",
    "                 num_iteration = 1000) -> None:\n",
    "        from scipy.special import gammaincc, gamma\n",
    "        self.data = data\n",
    "        self.mask = mask\n",
    "\n",
    "        self.a = a\n",
    "        self.b = b\n",
    "        self.theta = np.array([[self.a], [self.b]])\n",
    "\n",
    "        self.num_iteration = num_iteration\n",
    "        self.gammaincc = gammaincc\n",
    "        self.gamma = gamma\n",
    "        self.E_steps={\"Integrate\": self.E_step, \"MonteCarol\": self.MC_E_step}\n",
    "\n",
    "    def value(self, theta, data):\n",
    "        a = theta[0, 0]\n",
    "        b = theta[1, 0]\n",
    "\n",
    "        return np.sum(np.log(a) + np.log(b) + (b-1)*np.log(data) - a*data**b)\n",
    "    \n",
    "    def grad(self, theta, data):\n",
    "        a = theta[0, 0]\n",
    "        b = theta[1, 0]\n",
    "        tmp = np.log(data)\n",
    "        grad_a = np.sum(1/a - data**b)\n",
    "        grad_b = np.sum(1/b + tmp - a*data**(b)*tmp)\n",
    "        grad = np.array([[grad_a],[grad_b]])\n",
    "\n",
    "        return grad\n",
    "    \n",
    "    def hessian(self, theta, data):\n",
    "        a = theta[0, 0]\n",
    "        b = theta[1, 0]\n",
    "        tmp = np.log(data)\n",
    "        grad_aa = np.sum(-1/a**2)\n",
    "        grad_ab = np.sum(-data**(b)*tmp)\n",
    "        grad_bb = np.sum(-1/b**2 - a*data**(b)*tmp**2)\n",
    "        hessian = np.array([[grad_aa, grad_ab], [grad_ab, grad_bb]])\n",
    "\n",
    "        return hessian\n",
    "    \n",
    "    def grad_b(self, theta, data):\n",
    "        a = theta[0, 0]\n",
    "        b = theta[1, 0]\n",
    "        tmp = np.log(data)\n",
    "        return np.sum(1/b + tmp - a*data**(b)*tmp)\n",
    "    \n",
    "    def grad_b2(self, theta, data):\n",
    "        a = theta[0, 0]\n",
    "        b = theta[1, 0]\n",
    "        tmp = np.log(data)\n",
    "        return np.sum(-1/b**2 - a*data**(b)*tmp**2)\n",
    "    \n",
    "    def E_step(self, data, mask, theta):\n",
    "        tmp_data = data.copy()\n",
    "        tmp_mask = mask.copy()\n",
    "\n",
    "        a = theta[0, 0]\n",
    "        b = theta[1, 0]\n",
    "        idx = np.where(tmp_mask==1)\n",
    "\n",
    "        tmp1 = 1+1/b\n",
    "        tmp2 = a*tmp_data[idx]**b\n",
    "        tmp_data[idx] = tmp_data[idx]*(tmp2**(-1/b))*(self.gammaincc(tmp1, tmp2)*self.gamma(tmp1))\n",
    "\n",
    "        return tmp_data, tmp_mask\n",
    "    \n",
    "    def MC_E_step(self, data, mask, theta, sample_size = 10000):\n",
    "        from numpy.random import default_rng\n",
    "        tmp_data = data.copy()\n",
    "        tmp_mask = mask.copy()\n",
    "        idx = np.where(tmp_mask==1)\n",
    "        a = theta[0, 0]\n",
    "        b = theta[1, 0]\n",
    "        lamda = (1/a)**(1/b)\n",
    "\n",
    "        rng = default_rng()\n",
    "        for i in idx[0]:\n",
    "            threshold = tmp_data[i]\n",
    "            count = 0\n",
    "            samples = []\n",
    "            while(count < sample_size):\n",
    "                tmp_samples = lamda*rng.weibull(b, size=sample_size - count)\n",
    "                tmp_samples = tmp_samples[np.where(tmp_samples>=threshold)]\n",
    "                samples.append(tmp_samples)\n",
    "                count += tmp_samples.shape[0]\n",
    "            samples = np.concatenate(samples)\n",
    "            tmp_data[i] = np.mean(samples)\n",
    "        \n",
    "        return tmp_data, tmp_mask\n",
    "    \n",
    "    def gradient_M_step(self, data, theta, delta = 1e-10):\n",
    "        tmp_data = data.copy()\n",
    "        a = theta[0, 0]\n",
    "        b = theta[1, 0]\n",
    "\n",
    "        a = 1/np.mean(tmp_data**b)\n",
    "        tmp_theta = np.array([[a], [b]])\n",
    "        error = 1\n",
    "        while(error > delta):\n",
    "            '''\n",
    "            grad = self.grad(tmp_theta, tmp_data)\n",
    "            hessian = self.hessian(tmp_theta, tmp_data)\n",
    "            hessian_inv = np.linalg.inv(hessian)\n",
    "            delta_theta = -grad.T@hessian_inv\n",
    "            tmp_theta = tmp_theta + delta_theta\n",
    "            error = np.sqrt(np.sum(delta_theta**2))\n",
    "            print(error)\n",
    "            '''\n",
    "            grad = self.grad_b(tmp_theta, tmp_data)\n",
    "            hessian = self.grad_b2(tmp_theta, tmp_data)\n",
    "            hessian_inv = 1/hessian\n",
    "            delta_b = -grad*hessian_inv\n",
    "            tmp_b = tmp_theta[1,0] + delta_b\n",
    "            error = np.sqrt((tmp_b-tmp_theta[1,0])**2)\n",
    "            tmp_theta = np.array([[a],[tmp_b]])\n",
    "\n",
    "        return tmp_theta\n",
    "    \n",
    "    def EM_algorithm(self, data, mask, epsilon=1e-10, inplace=False, E_step = \"Integrate\"):\n",
    "        tmp_data = data.copy()\n",
    "        theta = self.theta\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_data, tmp_mask = self.E_steps[E_step](tmp_data, mask, theta)\n",
    "            tmp_theta = self.gradient_M_step(tmp_data, theta)\n",
    "            delta_theta = tmp_theta - theta\n",
    "            error = np.sqrt(np.sum(delta_theta**2)) \n",
    "            theta = tmp_theta\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.theta = theta\n",
    "            self.data = tmp_data\n",
    "        return theta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([6.94, 5.50, 4.54, 2.14, 3.65, 3.40, 4.38, 10.24, 4.56, 9.42, 4.55, 4.15, 5.64, 10.23])\n",
    "mask = np.array([1,0,0,0,1,1,1,0,0,0,1,1,0,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "coupling = Coupling(data, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM算法得到的预测值为, a = 0.013325, b = 2.484870\n"
     ]
    }
   ],
   "source": [
    "theta_coup = coupling.EM_algorithm(data, mask)\n",
    "print(\"EM算法得到的预测值为, a = %f, b = %f\"%(theta_coup[0,0], theta_coup[1,0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
