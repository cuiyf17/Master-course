{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sympy as sp\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Moth():\n",
    "    def __init__(self, X = [85, 196, 341, 578], num_iteration=100) -> None:\n",
    "        self.X = np.array(X)\n",
    "        self.sum_ = np.sum(X)\n",
    "        self.n = np.zeros(9)\n",
    "        self.p = 1/3*np.ones(3)\n",
    "        self.num_iteration = num_iteration\n",
    "\n",
    "    def E_step(self, x, p):\n",
    "        dom_p1 = p[0]**2+2*p[0]*p[1]+2*p[0]*p[2]\n",
    "        dom_p2 = p[1]**2+2*p[1]*p[2]\n",
    "        dom_p3 = dom_p2+p[2]**2\n",
    "\n",
    "        n_cc = x[0]*p[0]**2/dom_p1\n",
    "        n_ci = 2*x[0]*p[0]*p[1]/dom_p1\n",
    "        n_ct = 2*x[0]*p[0]*p[2]/dom_p1\n",
    "        n_ii = x[1]*p[1]**2/dom_p2\n",
    "        n_it = 2*x[1]*p[1]*p[2]/dom_p2\n",
    "        n_tt = x[2]\n",
    "        n_uii = x[3]*p[1]**2/dom_p3\n",
    "        n_uit = 2*x[3]*p[1]*p[2]/dom_p3\n",
    "        n_utt = x[3]*p[2]**2/dom_p3\n",
    "\n",
    "        n = np.array([n_cc, n_ci, n_ct, n_ii, n_it, n_tt, n_uii, n_uit, n_utt])\n",
    "        \n",
    "        return n\n",
    "    \n",
    "    def M_step(self, x, n):\n",
    "        sum_ = np.sum(x)\n",
    "        p_c = (2*n[0]+n[1]+n[2])/(2*sum_)\n",
    "        p_i = (2*n[3]+n[4]+n[1]+2*n[6]+n[7])/(2*sum_)\n",
    "        p_t = (2*n[5]+n[4]+n[2]+2*n[8]+n[7])/(2*sum_)\n",
    "        p = np.array([p_c, p_i, p_t])\n",
    "\n",
    "        return p\n",
    "    \n",
    "    def l(self, x, p):\n",
    "        return x[0]*np.log(p[0]**2 + 2*p[0]*p[1] + 2*p[0]*p[2]) + x[1]*np.log(p[1]**2+2*p[1]*p[2]) + 2*x[2]*np.log(p[2]) + 2*x[3]*np.log(p[1]+p[2])\n",
    "    \n",
    "    def grad_Q(self, n, p):\n",
    "        dp_c = (2*n[0]+n[1]+n[2])/p[0] - (n[2]+n[4]+n[7]+2*(n[5]+n[8]))/p[2]\n",
    "        dp_i = (n[1]+2*(n[3]+n[6])+n[4]+n[7])/p[1] - (n[2]+n[4]+n[7]+2*(n[5]+n[8]))/p[2]\n",
    "        return np.array([dp_c, dp_i])\n",
    "    \n",
    "    def hessian_Q(self, n, p):\n",
    "        dp_cc = -(2*n[0]+n[1]+n[2])/(p[0]**2) - (n[2]+n[4]+n[7]+2*(n[5]+n[8]))/(p[2]**2)\n",
    "        dp_ci = -(n[2]+n[4]+n[7]+2*(n[5]+n[8]))/(p[2]**2)\n",
    "        dp_ii = -(n[1]+2*(n[3]+n[6])+n[4]+n[7])/(p[1]**2) - (n[2]+n[4]+n[7]+2*(n[5]+n[8]))/(p[2]**2)\n",
    "        return np.array([[dp_cc, dp_ci],[dp_ci, dp_ii]])\n",
    "    \n",
    "    def StepHalvingBacktracking(self, x, p0, D):\n",
    "        t_tmp = 1\n",
    "        p_dim = p0.shape[0]\n",
    "        l0 = self.l(x, p0)\n",
    "        tmp_p = np.zeros(p0.shape)\n",
    "        tmp_p[:2] = p0[:2] + t_tmp*D\n",
    "        tmp_p[2] = 1 - np.sum(tmp_p[:2])\n",
    "        \n",
    "        while((np.sum(tmp_p >= 0)<p_dim) or (np.sum(tmp_p <= 1)<p_dim)):\n",
    "            t_tmp = 0.5*t_tmp\n",
    "            tmp_p = np.zeros(p0.shape)\n",
    "            tmp_p[:2] = p0[:2] + t_tmp*D\n",
    "            tmp_p[2] = 1 - np.sum(tmp_p[:2])\n",
    "\n",
    "        while(self.l(x, tmp_p) < l0):\n",
    "            t_tmp = 0.5*t_tmp\n",
    "            tmp_p = np.zeros(p0.shape)\n",
    "            tmp_p[:2] = p0[:2] + t_tmp*D\n",
    "            tmp_p[2] = 1 - np.sum(tmp_p[:2])\n",
    "\n",
    "        return tmp_p\n",
    "    \n",
    "    def gradient_M_step(self, x, n, p):\n",
    "        tmp_p = p.copy()\n",
    "        hessian_inv = np.linalg.inv(self.hessian_Q(n, tmp_p))\n",
    "        grad = self.grad_Q(n, tmp_p)\n",
    "        delta__nt = -hessian_inv@grad\n",
    "        tmp_p = self.StepHalvingBacktracking(x, tmp_p, delta__nt)\n",
    "\n",
    "        return tmp_p\n",
    "\n",
    "    def EM_algorithm(self, X, epsilon=1e-10, inplace=False):\n",
    "        n, p = self.n, self.p\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_n = self.E_step(X, p)\n",
    "            tmp_p = self.M_step(X, tmp_n)\n",
    "            delta_n = tmp_n - n\n",
    "            delta_p = tmp_p - p\n",
    "            p, n = tmp_p, tmp_n\n",
    "            error = np.sqrt(np.sum(delta_n**2)) + np.sqrt(np.sum(delta_p**2))\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.p, self.n = p, n\n",
    "\n",
    "        return p\n",
    "    \n",
    "    def BootStrap_p(self, num_bootstrap):\n",
    "        P = np.zeros((num_bootstrap, self.p.shape[0]))\n",
    "        for i in range(num_bootstrap):\n",
    "            n_c = np.random.binomial(self.sum_, self.X[0]/self.sum_, size=None)\n",
    "            n_i = np.random.binomial(self.sum_-n_c, self.X[1]/(self.sum_-n_c), size=None)\n",
    "            n_t = np.random.binomial(self.sum_-n_c-n_i, self.X[2]/(self.sum_-n_c-n_i), size=None)\n",
    "            n_u = self.sum_-n_c-n_t-n_i\n",
    "\n",
    "            x_generated = np.array([n_c, n_i, n_t, n_u])\n",
    "            p = self.EM_algorithm(x_generated, inplace=False)\n",
    "            P[i] = p\n",
    "            \n",
    "        return P\n",
    "    \n",
    "    def cal_p_statistic(self, num_bootstrap):\n",
    "        P = self.BootStrap_p(num_bootstrap)\n",
    "        p_mean = np.mean(P, axis=0)\n",
    "        p_std = np.std(P, axis=0)\n",
    "        cov = np.cov(P.T)\n",
    "        cor = np.corrcoef(P.T)\n",
    "        return p_mean, p_std, cov, cor\n",
    "    \n",
    "    def EM_gradient_algorithm(self, X, epsilon=1e-10, inplace=False):\n",
    "        n, p = self.n, self.p\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_n = self.E_step(X, p)\n",
    "            tmp_p = self.gradient_M_step(X, tmp_n, p)\n",
    "            delta_n = tmp_n - n\n",
    "            delta_p = tmp_p - p\n",
    "            p, n = tmp_p, tmp_n\n",
    "            error = np.sqrt(np.sum(delta_n**2)) + np.sqrt(np.sum(delta_p**2))\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.p, self.n = p, n\n",
    "        return p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = [85, 196, 341, 578]\n",
    "moth = Moth(X, num_iteration=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM算法得到的p的MLE为: p_c = 0.036067, p_i = 0.195799, p_t = 0.768134\n"
     ]
    }
   ],
   "source": [
    "MLE_EM = moth.EM_algorithm(X, inplace=True)\n",
    "print(\"EM算法得到的p的MLE为: p_c = %f, p_i = %f, p_t = %f\"%(MLE_EM[0], MLE_EM[1], MLE_EM[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 10000\n",
    "p_mean, p_std, p_cov, p_cor = moth.cal_p_statistic(num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boot strapping采样10000次后得到:\n",
      "p_c, p_i, p_t的标准差分别为0.003865, 0.010986, 0.011390\n",
      "p的相关系数矩阵为:\n",
      " [[ 1.         -0.06959851 -0.27221216]\n",
      " [-0.06959851  1.         -0.94095835]\n",
      " [-0.27221216 -0.94095835  1.        ]]\n",
      "可见, corr(p_c, p_i) = -0.069599, corr(p_c, p_t) = -0.272212, corr(p_i, p_t) = -0.940958\n"
     ]
    }
   ],
   "source": [
    "std_p_c, std_p_i, std_p_t = np.sqrt(p_cov[0,0]), np.sqrt(p_cov[1,1]), np.sqrt(p_cov[2,2])\n",
    "print(\"Boot strapping采样%d次后得到:\"%(num_iterations))\n",
    "print(\"p_c, p_i, p_t的标准差分别为%f, %f, %f\"%(std_p_c, std_p_i, std_p_t))\n",
    "print(\"p的相关系数矩阵为:\\n\", p_cor)\n",
    "print(\"可见, corr(p_c, p_i) = %f, corr(p_c, p_t) = %f, corr(p_i, p_t) = %f\"%(p_cor[0,1], p_cor[0,2], p_cor[1,2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EM gradient算法得到的p的MLE为: p_c = 0.036067, p_i = 0.195799, p_t = 0.768134\n"
     ]
    }
   ],
   "source": [
    "MLE_EM_grad = moth.EM_gradient_algorithm(X, inplace=False)\n",
    "print(\"EM gradient算法得到的p的MLE为: p_c = %f, p_i = %f, p_t = %f\"%(MLE_EM_grad[0], MLE_EM_grad[1], MLE_EM_grad[2]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HIV():\n",
    "    def __init__(self, X = [379,299,222,145,109,95,73,59,45,30,24,12,4,2,0,1,1], num_iteration=10000) -> None:\n",
    "        from scipy.special import gamma\n",
    "        self.X = np.array(X)\n",
    "        self.sum_ = np.sum(X)\n",
    "        self.alpha, self.beta, self.mu, self.lamda = 1/3, 1/3, 0.5, 0.5\n",
    "        self.theta = (self.alpha, self.beta, self.mu, self.lamda)\n",
    "\n",
    "        self.I = np.arange(0, self.X.shape[0], 1)\n",
    "        self.zi = np.zeros(self.I.shape[0])\n",
    "        self.ti = np.zeros(self.I.shape[0])\n",
    "        self.pi = np.zeros(self.I.shape[0])\n",
    "\n",
    "        self.F_gamma = gamma\n",
    "        self.num_iteration = num_iteration\n",
    "\n",
    "    def E_step(self, theta):\n",
    "        alpha, beta, mu, lamda = theta\n",
    "\n",
    "        I = np.arange(0, 17, 1)\n",
    "        zi = alpha*((I==0).astype(np.int32))\n",
    "        ti = beta*np.exp(-mu)*(mu**I)\n",
    "        pi = (1-alpha-beta)*np.exp(-lamda)*(lamda**I)\n",
    "        PI = zi+ti+pi\n",
    "\n",
    "        zi /= PI\n",
    "        ti /= PI\n",
    "        pi /= PI\n",
    "\n",
    "        return I, zi, ti, pi\n",
    "\n",
    "    def M_step(self, x, p):\n",
    "        I, zi, ti, pi = p\n",
    "\n",
    "        sum_ = np.sum(x)\n",
    "        alpha = np.sum(x[0]*zi)/sum_\n",
    "        beta = np.sum(x*ti)/sum_\n",
    "        mu = np.sum(I*x*ti)/np.sum(x*ti)\n",
    "        lamda = np.sum(I*x*pi)/np.sum(x*pi)\n",
    "        theta = (alpha, beta, mu, lamda)\n",
    "        \n",
    "        return theta\n",
    "\n",
    "    def EM_algorithm(self, X, epsilon=1e-10, inplace=False):\n",
    "        theta = (self.alpha, self.beta, self.mu, self.lamda)\n",
    "        p = self.I, self.zi, self.ti, self.pi\n",
    "\n",
    "        for i in range(1, self.num_iteration+1, 1):\n",
    "            tmp_p = self.E_step(theta)\n",
    "            tmp_theta = self.M_step(X, tmp_p)\n",
    "            delta_theta = np.array(tmp_theta) - np.array(theta)\n",
    "            delta_p = np.concatenate([tmp_p[j] - p[j] for j in range(len(tmp_p))])\n",
    "            error = np.sqrt(np.sum(delta_theta**2)) + np.sqrt(np.sum(delta_p**2))\n",
    "            p, theta = tmp_p, tmp_theta\n",
    "            if(error < epsilon):\n",
    "                break\n",
    "        if(error >= epsilon):\n",
    "            print(\"算法没收敛\")\n",
    "        if(inplace):\n",
    "            self.I, self.zi, self.ti, self.pi = p\n",
    "            self.theta = theta\n",
    "\n",
    "        return theta\n",
    "    \n",
    "    def BootStrap_theta(self, num_bootstrap):\n",
    "        P = np.zeros((num_bootstrap, len(self.theta)))\n",
    "        for i in range(num_bootstrap):\n",
    "            x_generated = np.zeros(self.X.shape)\n",
    "            x_sampled = np.random.choice(np.arange(self.X.shape[0]), np.sum(self.X), p=self.X/np.sum(self.X))\n",
    "            for j in range(x_generated.shape[0]):\n",
    "                x_generated[j] = np.where(x_sampled == j)[0].shape[0]\n",
    "            theta = self.EM_algorithm(x_generated, inplace=False)\n",
    "            P[i] = np.array(theta)\n",
    "            \n",
    "        return P\n",
    "    \n",
    "    def cal_p_statistic(self, num_bootstrap):\n",
    "        P = self.BootStrap_theta(num_bootstrap)\n",
    "        p_mean = np.mean(P, axis=0)\n",
    "        p_std = np.std(P, axis=0)\n",
    "        cov = np.cov(P.T)\n",
    "        cor = np.corrcoef(P.T)\n",
    "        return p_mean, p_std, cov, cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([379,299,222,145,109,95,73,59,45,30,24,12,4,2,0,1,1])\n",
    "hiv = HIV(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测的alpha = 0.122166, beta = 0.562542, mu = 1.467475, lambda = 5.938889\n"
     ]
    }
   ],
   "source": [
    "theta_pred = hiv.EM_algorithm(data, inplace=True)\n",
    "print(\"预测的alpha = %f, beta = %f, mu = %f, lambda = %f\"%theta_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iterations = 2000\n",
    "theta_mean, theta_std, theta_cov, theta_cor = hiv.cal_p_statistic(num_iterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Boot strapping采样2000次后得到:\n",
      "alpha, beta, mu, lambda的标准差分别为0.044415, 0.089679, 1.325910, 1.452198\n",
      "theta的相关系数矩阵为:\n",
      " [[ 1.         -0.59179758  0.39238327 -0.40846613]\n",
      " [-0.59179758  1.         -0.94386978  0.9611617 ]\n",
      " [ 0.39238327 -0.94386978  1.         -0.9805038 ]\n",
      " [-0.40846613  0.9611617  -0.9805038   1.        ]]\n",
      "可见,\n",
      "corr(alpha, beta) = -0.591798,\tcorr(alpha, mu) = 0.392383,\tcorr(alpha, lambda) = -0.408466,\n",
      "corr(beta, mu) = -0.943870,\tcorr(beta, lambda) = 0.961162,\tcorr(mu, lambda) = -0.980504\n"
     ]
    }
   ],
   "source": [
    "std_alpha, std_beta, std_mu, std_lambda = np.sqrt(theta_cov[0,0]), np.sqrt(theta_cov[1,1]), np.sqrt(theta_cov[2,2]), np.sqrt(theta_cov[3,3])\n",
    "print(\"Boot strapping采样%d次后得到:\"%(num_iterations))\n",
    "print(\"alpha, beta, mu, lambda的标准差分别为%f, %f, %f, %f\"%(std_alpha, std_beta, std_mu, std_lambda))\n",
    "print(\"theta的相关系数矩阵为:\\n\", theta_cor)\n",
    "print(\"可见,\\ncorr(alpha, beta) = %f,\\tcorr(alpha, mu) = %f,\\tcorr(alpha, lambda) = %f,\\ncorr(beta, mu) = %f,\\tcorr(beta, lambda) = %f,\\tcorr(mu, lambda) = %f\"%(theta_cor[0,1], theta_cor[0,2], theta_cor[0,3], theta_cor[1,2], theta_cor[1,3], theta_cor[2,3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
