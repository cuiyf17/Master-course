{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "#%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_file = \"data_HC/menon_train_data.csv\"\n",
    "train_label_file = \"data_HC/menon_train_label.csv\"\n",
    "valid_data_file = \"data_HC/menon_validation_data.csv\"\n",
    "valid_label_file = \"data_HC/menon_validation_label.csv\"\n",
    "test_data_file = \"data_HC/lukowski_test_data.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes_tree = pd.read_csv(\"data_HC/classes_tree.csv\").fillna(\"Unknown\")\n",
    "classes_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_levels = classes_tree.shape[1]\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "N_EPOCHS = 60\n",
    "LR = 2e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BuildTree(classes_tree):\n",
    "    n_levels = classes_tree.shape[1]\n",
    "    label_tree = dict()\n",
    "    lv_name = ['Level ' + str(i) if i != 0 else 'Root' for i in range(n_levels)]\n",
    "    curr_path = []\n",
    "    for i in range(classes_tree.shape[0]):\n",
    "        for j in range(len(lv_name)):\n",
    "            class_name = classes_tree[lv_name[j]][i]\n",
    "            if class_name != 'Unknown':\n",
    "                curr_node = label_tree\n",
    "                curr_path = curr_path[:j]\n",
    "                for p in curr_path:\n",
    "                    curr_node = curr_node[p]\n",
    "                curr_node[class_name] = dict()\n",
    "                curr_path.append(class_name)\n",
    "    return label_tree\n",
    "label_tree = BuildTree(classes_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Get_level_label(n_levels = n_levels, classes_tree = classes_tree):\n",
    "    level_label = dict()\n",
    "    for i in range(n_levels):\n",
    "        labels = np.unique(classes_tree.iloc[:,i])\n",
    "        level_label[i] = dict()\n",
    "        for j in range(labels.shape[0]):\n",
    "            level_label[i][labels[j]] = np.eye(labels.shape[0])[j]\n",
    "    return level_label\n",
    "\n",
    "level_label = Get_level_label(n_levels, classes_tree)\n",
    "level_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_df = pd.read_csv(train_data_file, index_col=0).fillna(\"Unknown\")\n",
    "train_label_df = pd.read_csv(train_label_file, index_col=0).fillna(\"Unknown\")\n",
    "valid_data_df = pd.read_csv(valid_data_file, index_col=0).fillna(\"Unknown\")\n",
    "valid_label_df = pd.read_csv(valid_label_file, index_col=0).fillna(\"Unknown\")\n",
    "test_data_df = pd.read_csv(test_data_file, index_col=0).fillna(\"Unknown\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_label_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = np.mean(train_data_df, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseCrossEntropy(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(DenseCrossEntropy, self).__init__()\n",
    "        \n",
    "        \n",
    "    def forward(self, logits, labels):\n",
    "        logits = logits.float()\n",
    "        labels = labels.float()\n",
    "        \n",
    "        logprobs = F.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        loss = -labels * logprobs\n",
    "        loss = loss.sum(-1)\n",
    "\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CellModel(nn.Module):\n",
    "    def __init__(self, input_size=2000, output_size=256):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 1024)\n",
    "        nn.init.kaiming_normal_(self.fc1.weight) # OPTIONAL\n",
    "        self.fc2 = nn.Linear(1024, 512)\n",
    "        nn.init.kaiming_normal_(self.fc2.weight) # OPTIONAL\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight) # OPTIONAL\n",
    "        self.fc4 = nn.Linear(512, 256)\n",
    "        nn.init.kaiming_normal_(self.fc3.weight) # OPTIONAL\n",
    "        #self.fc5 = nn.Linear(128, 64)\n",
    "        #nn.init.kaiming_normal_(self.fc3.weight) # OPTIONAL\n",
    "        #self.fc6 = nn.Linear(64, 32)\n",
    "        #nn.init.kaiming_normal_(self.fc3.weight) # OPTIONAL\n",
    "               \n",
    "    def forward(self, x):\n",
    "        # forward always defines connectivity\n",
    "        x = x.squeeze(-1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        output1 = F.relu(self.fc4(x))\n",
    "        #output2 = F.relu(self.fc4(output1))\n",
    "        #output3 = F.relu(self.fc5(output2))\n",
    "        #output4 = F.relu(self.fc6(output3))\n",
    "        return output1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierNode:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.children = list()\n",
    "        self.children_name = dict()\n",
    "    \n",
    "    def AddChild(self, child_node):\n",
    "        self.children_name[child_node.name] = len(self.children)\n",
    "        self.children.append(child_node)\n",
    "    \n",
    "    def BuildClassifier(self):\n",
    "        if len(self.children) > 0:\n",
    "            unknown_node = ClassifierNode('Unknown ' + self.name)\n",
    "            unknown_node.BuildClassifier()\n",
    "            self.AddChild(unknown_node)\n",
    "            self.classifier = nn.Linear(256, len(self.children))\n",
    "        else:\n",
    "            self.classifier = None\n",
    "    \n",
    "    def GetClfList(self):\n",
    "        if self.classifier is not None:\n",
    "            clf_list = [self.classifier, ]\n",
    "            for child in self.children:\n",
    "                clf_list += child.GetClfList()\n",
    "            return clf_list\n",
    "        else:\n",
    "            return list()\n",
    "    \n",
    "    def GetClfName(self):\n",
    "        if self.classifier is not None:\n",
    "            name_list = [list(self.children_name.keys()), ]\n",
    "            for child in self.children:\n",
    "                name_list += child.GetClfName()\n",
    "            return name_list\n",
    "        else:\n",
    "            return list()\n",
    "    \n",
    "    def to(self, device):\n",
    "        if self.classifier:\n",
    "            self.classifier.to(device)\n",
    "            for child in self.children:\n",
    "                child.to(device)\n",
    "    \n",
    "    def parameters(self):\n",
    "        if self.classifier:\n",
    "            for p in self.classifier.parameters():\n",
    "                yield p\n",
    "            for child in self.children:\n",
    "                for p in child.parameters():\n",
    "                    yield p\n",
    "    \n",
    "    def classify(self, x):\n",
    "        types = np.full(len(x), '', dtype=object)\n",
    "        if self.classifier:\n",
    "            clf_output = self.classifier(x).detach().cpu().numpy()\n",
    "            clf_output = np.argmax(clf_output, axis=1)\n",
    "            for name, idx in self.children_name.items():\n",
    "                types[clf_output==idx] = name + ','\n",
    "                child_result = self.children[idx].classify(x[clf_output==idx])\n",
    "                types[clf_output==idx] += child_result\n",
    "        return types\n",
    "\n",
    "\n",
    "\n",
    "def BuildClassifiers(node_name, tree):\n",
    "    root_node = ClassifierNode(node_name)\n",
    "    for key, val in tree.items():\n",
    "        child_node = BuildClassifiers(key, val)\n",
    "        root_node.AddChild(child_node)\n",
    "    root_node.BuildClassifier()\n",
    "    return root_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = BuildClassifiers(list(label_tree.keys())[0], list(label_tree.values())[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.GetClfName()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\")\n",
    "model = CellModel().to(device)\n",
    "root.to(device)\n",
    "criterion = DenseCrossEntropy()\n",
    "plist = [\n",
    "    {'params': model.parameters(), 'lr': LR},\n",
    "    {'params': root.parameters(), 'lr': LR}\n",
    "]\n",
    "optimizer = optim.Adam(plist, lr=LR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MEAN = 0\n",
    "STD = 0\n",
    "class CellDataset(Dataset):\n",
    "    def __init__(self, data_df, label_df, clf_target, is_train = True, mean = None, std = None):\n",
    "        self.data_df = data_df\n",
    "        self.label_df = label_df\n",
    "        self.clf_target = clf_target\n",
    "        self.mean = None\n",
    "        self.std = None\n",
    "        if(is_train):\n",
    "            self.mean = np.mean(data_df, axis = 0)\n",
    "            self.std = np.std(data_df, axis = 0)\n",
    "        else:\n",
    "            self.mean = mean\n",
    "            self.std = std\n",
    "        #self.data_df = (self.data_df-self.mean)/(self.std+1e-12)\n",
    "        MEAN = self.mean\n",
    "        STD = self.std\n",
    "    def __len__(self):\n",
    "        return self.data_df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data_df.iloc[idx,:].astype(np.float32)\n",
    "        data = torch.from_numpy(np.array(data))\n",
    "        str_label = self.label_df.iloc[idx,:]\n",
    "        labels = [np.zeros(len(k), dtype=np.float32) for k in self.clf_target]\n",
    "        weight = np.zeros(len(self.clf_target), dtype=np.float32)\n",
    "        for lb_id, lb_name in enumerate(str_label):\n",
    "            found_unknown = True\n",
    "            if lb_name == 'Unknown' and lb_id > 0 and str_label[lb_id - 1] != 'Unknown':\n",
    "                lb_name = 'Unknown ' + str_label[lb_id - 1]\n",
    "            for i in range(len(self.clf_target)):\n",
    "                if lb_name in self.clf_target[i]:\n",
    "                    idx = self.clf_target[i].index(lb_name)\n",
    "                    labels[i][idx] = 1.\n",
    "                    weight[i] = 1.\n",
    "                    \n",
    "        labels = [torch.from_numpy(lb) for lb in labels]\n",
    "        weight = torch.from_numpy(weight)\n",
    "\n",
    "        return data, [labels, weight]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CellDataset(train_data_df, train_label_df, root.GetClfName(), is_train = True)\n",
    "training_data, validation_data = random_split(dataset_train, [len(dataset_train) - 1024, 1024])\n",
    "dataloader_train = DataLoader(training_data, batch_size=BATCH_SIZE, num_workers=0, shuffle=True)\n",
    "dataloader_valid = DataLoader(validation_data, batch_size=1024, num_workers=0, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root.GetClfList()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model = model, classifiers = root, criterion = criterion, optimizer = optimizer,\n",
    "          dataloader = dataloader_train, validloader = dataloader_valid):\n",
    "    clf_list = classifiers.GetClfList()\n",
    "    for epoch in range(N_EPOCHS):\n",
    "        model.train()\n",
    "        [clf.train() for clf in clf_list]\n",
    "        tr_loss = 0\n",
    "        \n",
    "        for step, batch in enumerate(dataloader):\n",
    "            data = batch[0].to(device)\n",
    "            label, weight = batch[1]\n",
    "            weight = weight.to(device)\n",
    "            for i in range(len(label)):\n",
    "                label[i] = label[i].to(device)\n",
    "                \n",
    "            output = model(data)\n",
    "            loss = None\n",
    "            for i in range(len(clf_list)):\n",
    "                result = clf_list[i](output)\n",
    "                if(loss is None):\n",
    "                    loss = weight[:, i:i+1] * criterion(result, label[i].squeeze(-1))\n",
    "                else:\n",
    "                    loss += weight[:, i:i+1] * criterion(result, label[i].squeeze(-1))\n",
    "            \n",
    "            loss = loss.sum()\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            tr_loss += loss.item()\n",
    "            optimizer.step()\n",
    "            print(\"Epoch %d, step %d, loss = %.4f\"%(epoch, step, loss))\n",
    "        \n",
    "        model.eval()\n",
    "        [clf.eval() for clf in clf_list]\n",
    "        val_preds = [None] * len(clf_list)\n",
    "        val_labels = [None] * len(clf_list)\n",
    "        valid_samples = [0] * len(clf_list)\n",
    "        total_samples = [0] * len(clf_list)\n",
    "        \n",
    "        for step, batch in enumerate(validloader):\n",
    "            data = batch[0].to(device)\n",
    "            label, weight = batch[1]\n",
    "            weight = weight.to(device)\n",
    "            for i in range(len(label)):\n",
    "                valid_samples[i] += float(torch.sum(weight[:, i]))\n",
    "                total_samples[i] += len(weight)\n",
    "                label[i] = label[i].to(device)\n",
    "                if val_labels[i] is None:\n",
    "                    val_labels[i] = label[i].clone().data.cpu()\n",
    "                else:\n",
    "                    val_labels[i] = torch.cat((val_labels[i], label[i].clone().data.cpu()), dim=0)\n",
    "                \n",
    "            output = model(data)\n",
    "            loss = None\n",
    "            for i in range(len(clf_list)):\n",
    "                result = clf_list[i](output)\n",
    "                if(loss is None):\n",
    "                    loss = weight[:, i:i+1] * criterion(result, label[i].squeeze(-1))\n",
    "                else:\n",
    "                    loss += weight[:, i:i+1] * criterion(result, label[i].squeeze(-1))\n",
    "    \n",
    "                preds = (weight[:, i:i+1] * torch.softmax(result, dim=1)).data.cpu()\n",
    "                if(val_preds[i] is None):\n",
    "                    val_preds[i] = preds\n",
    "                else:\n",
    "                    val_preds[i] = torch.cat((val_preds[i], preds), dim=0)\n",
    "            \n",
    "        clf_accu = []\n",
    "        for i in range(len(clf_list)):\n",
    "            correct_num = (torch.argmax(val_preds[i], dim=1)==torch.argmax(val_labels[i], dim=1)).sum()\n",
    "            clf_accu.append(1. - (total_samples[i] - correct_num) / valid_samples[i])\n",
    "            print(\"Epoch %d, clf%d, num_sample = %d, accu = %.4f\"%(epoch, i+1, valid_samples[i], clf_accu[i]))\n",
    "        print(\"------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_valid = CellDataset(valid_data_df, valid_label_df, root.GetClfName(), is_train = False, mean = MEAN, std = STD)\n",
    "dataloader_valid = DataLoader(dataset_valid, batch_size=BATCH_SIZE, num_workers=0, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(model = model, classifiers = root, criterion = criterion, dataloader = dataloader_valid):\n",
    "    clf_list = classifiers.GetClfList()\n",
    "    \n",
    "    model.eval()\n",
    "    [clf.eval() for clf in clf_list]\n",
    "\n",
    "    val_preds = [None] * len(clf_list)\n",
    "    val_labels = [None] * len(clf_list)\n",
    "    valid_samples = [0] * len(clf_list)\n",
    "    total_samples = [0] * len(clf_list)\n",
    "    for step, batch in enumerate(dataloader):\n",
    "        data = batch[0].to(device)\n",
    "        label, weight = batch[1]\n",
    "        weight = weight.to(device)\n",
    "        \n",
    "        for i in range(len(label)):\n",
    "            label[i] = label[i].to(device)\n",
    "            valid_samples[i] += float(torch.sum(weight[:, i]))\n",
    "            total_samples[i] += len(weight)\n",
    "            \n",
    "            if val_labels[i] is None:\n",
    "                val_labels[i] = label[i].clone().data.cpu()\n",
    "            else:\n",
    "                val_labels[i] = torch.cat((val_labels[i], label[i].clone().data.cpu()), dim=0)\n",
    "                \n",
    "        with torch.no_grad():       \n",
    "            output = model(data)\n",
    "            loss = None\n",
    "            for i in range(len(clf_list)):\n",
    "                result = clf_list[i](output)\n",
    "                preds = (weight[:, i:i+1] * torch.softmax(result, dim=1)).data.cpu()\n",
    "                if(val_preds[i] is None):\n",
    "                    val_preds[i] = preds\n",
    "                else:\n",
    "                    val_preds[i] = torch.cat((val_preds[i], preds), dim=0)\n",
    "        \n",
    "    level_auc = []\n",
    "    level_accu = []\n",
    "    for i in range(len(clf_list)):\n",
    "        #print(val_preds[i])\n",
    "        #if(torch.unique(val_preds[i], dim=0).shape[0]>1):\n",
    "        #    level_auc.append(roc_auc_score(val_preds[i], val_labels[i], average='macro'))\n",
    "        #else:\n",
    "        correct_num = (torch.argmax(val_preds[i], dim=1)==torch.argmax(val_labels[i], dim=1)).sum()\n",
    "        \n",
    "        level_auc.append(1)\n",
    "        level_accu.append(1. - (total_samples[i] - correct_num) / valid_samples[i])\n",
    "        print(\"clf%d, auc = %.4f, accu = %.4f\"%(i+1, level_auc[i], level_accu[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_data_torch = torch.tensor(valid_data_df.values).type(torch.float32).to(device)\n",
    "out = model(valid_data_torch)\n",
    "\n",
    "clf_ref = root.classify(out)\n",
    "clf_ref = [x.strip(',').split(',') for x in clf_ref]\n",
    "clf_ref = np.array([([s if s[:7] != 'Unknown' else 'Unknown' for s in x] + ['Unknown', ] * 4)[:4]\n",
    "                    for x in clf_ref], dtype=object)\n",
    "\n",
    "err_rate = np.mean(np.sum(clf_ref != valid_label_df.values, axis=1, dtype=bool))\n",
    "print(\"Total err rate on validation set is %.4f\"%(err_rate))\n",
    "\n",
    "np.savetxt('validset_result.csv', clf_ref, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data_torch = torch.tensor(test_data_df.values).type(torch.float32).to(device)\n",
    "out = model(test_data_torch)\n",
    "\n",
    "clf_ref = root.classify(out)\n",
    "clf_ref = [x.strip(',').split(',') for x in clf_ref]\n",
    "clf_ref = np.array([([s if s[:7] != 'Unknown' else 'Unknown' for s in x] + ['Unknown', ] * 4)[:4]\n",
    "                    for x in clf_ref], dtype=object)\n",
    "\n",
    "np.savetxt('testset_result.csv', clf_ref, fmt='%s', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
